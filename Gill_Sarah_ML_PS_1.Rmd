---
title: "Gill_Sarah_ML_PS_1"
author: "Sarah Gill"
date: "1/13/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop/Machine Learning/PS_1")
library(readr)
library(tidyverse)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
names(mtcars)
summary(mtcars)
```
1.
a. Predict miles per gallon (mpg) as a function of cylinders (cyl). What is the output and parameter values for your model?
```{r 1a}
# Here we regress wage on IQ and then on age, bivariate 
#lm(wage ~ IQ, data = wage)

model1 <- lm(mpg ~ cyl, data = mtcars)
summary(model1)
#predict(model1)

```
There is a statistically significant relationship between number of cylindars and mpg.
Each additional cylinder is associated with a decrease in miles per gallon of 2.876mpg. 
These results show a theoretical mpg of 37.88mpg for the impossible car that has no cylindars. 


??????
b. Write the statistical form of the simple model in the previous question (i.e., what is the population regression function?).

mpg = intercept + b*cyl + error


c.Add vehicle weight (wt) to the specification. Report the results and talk about differences in coefficient size, effects, etc.
```{r 1c}
model2 <- lm(mpg ~ cyl + wt, data = mtcars)
summary(model2)
#predict(model2)

```

There is a statistically significant relationship between number of cylindars and mpg and between weight and mpg. Each additional cylinder is associated with 1.508 fewer miles per gallon, holding weight constant. Each additional 1000lbs (one unit in wt) is associated with 3.191 fewer miles per gallon, holding number of cylinders constant. 

These results show a theoretical mpg of 39.69mpg for the impossible car that weighs nothing and has no cylindars. 

Note that the magnitude of the estimate for cyl is less than in the univariate regression. Some of the decrease in mpg that was associated with cly in the previous model may be better explained by weight.



d. Interact weight and cylinders and report the results. What is the same or different? What are we theoretically asserting by including a multiplicative interaction term in the function?

```{r 1d}
model3 <- lm(mpg ~ cyl*wt, data = mtcars) 
summary(model3)
#predict(model3)
```
When we include an interaction term for wt and cyl, the coefficient estimates for both wt and cyl increase in magnitude (they are both more negative). However these coefficients can no longer be interpreted on their own. By including an interaction term we are making the assertion that the relationship between weight and number of cylinders moderates or mediates the relationship between weight and mpg and between number of cylinders and mpg. In other words, we assert that the relationship between cylinders and mpg is effected by weight and the relationship between weight and mpg is effected by number of cylinders.
This assertion is supported by the results, with the estimate for the interaction term being statistically significant, and it's inclusion improving our Adjusted R-squared.
The estimated relationship is:


cyl on mpg:  -3.81 + 0.81*wt
wt on mpg:  -8.66 + 0.81*cyl

So for a car that is the mean weight in this dataset, an increase of one additional cylinder is associated with a decrease of roughly 1.20mpg.

mean wt in dataset: 3.217 

```{r}
 -3.8032 + 0.8084 *(3.217)
```
Or for a car that has the mean number of cylinders for this dataset, an increase of an additional 1000lbs (one unit of wt) is associated with a decrease of roughly 3.65mpg

mean cyl in dataset: 6.188
```{r}
-8.6556  + 0.8084 *(6.188)
```





2. Non-linear Regression
a. Fit a polynomial regression, predicting wage as a function of a second order polynomial for age. Report the results and discuss the output
```{r 2a}
wage_data <- read_csv("wage_data.csv")

wage_model <- lm(wage ~ age + I(age^2), data = wage_data)
#wage_model <- lm(wage ~ poly(age, degree = 2, raw = T), data = wage_data)
summary(wage_model)
```
c. Describe the output. What do you see substantively? What are we asserting by fitting a polynomial regression?

By fitting a polynomial to this data, we are asserting that the relationship between age and wage may be different at different ages. Using a quadratic function we are allowing for the relationship to be concave or convex and even to change signs.

Here we see that at lower ages increasing age is associated with increasing wage, however this is increasing at a decreasing rate (as indicated by the negative sign on the age^2 coefficient, thus our fitted curve is concave). Also the positive slope may change to negative at some age. 

increasing age by one year is associated with a change in wage of 5.29 - 0.053(age)

b. Plot the function with 95% confidence interval bounds.
```{r, warning=FALSE}
# plot
#works but throws an error
y = wage_data$wage
x = wage_data$age
plot(x,y,col=rgb(0.4,0.4,0.8,0.6),pch=16 , cex=1.3, xlab = "Wage", ylab = "Age") 

#myPredict <- predict( wage_model ) 
#ix <- sort(x,index.return=T)$ix
#lines(x[ix], myPredict[ix], col=2, lwd=2 ) 

#Curve
myPredict <- predict( wage_model , interval="predict")
ix <- sort(x,index.return=T)$ix
lines(x[ix], myPredict[ix , 1], col=2, lwd=2 )

CI <- predict(wage_model, x=wage, interval = 'confidence', level=0.95)
#CI <- predict( wage_model , interval="confidence", level=0.95 )
#ix <- sort(x,index.return=T)$ix
#lines(x[ix], CI[ix , 1], col=2, lwd=2 )
#CI
polygon(c(rev(x[ix]), x[ix]), c(rev(CI[ ix,3]), CI[ ix,2]), col = rgb(0.7,0.7,0.7,0.4) , border = "black", alpha = 1)

#cite: https://www.r-graph-gallery.com/44-polynomial-curve-fitting.html
#cite: https://www.r-graph-gallery.com/45-confidence-interval-around-polynomial-curve-fitting.html
#cite: https://www.researchgate.net/post/How_can_I_put_confidence_intervals_in_R_plot
```
From the plot we can see that wage increases with age until about 50, when each additional year of age is then associated with a decrease in wage. 


```{r}
y = wage_data$wage
x = wage_data$age
plot(x,y,col=rgb(0.4,0.4,0.8,0.6),pch=16 , cex=1.3) 
m = wage_model
wx = par("usr")[1:2]
new.x = seq(wx[1],wx[2],len=100)
pred = predict(m, new=data.frame(x=new.x), interval="conf")
polygon(c(new.x,rev(new.x)),c(pred[,"lwr"],rev(pred[,"upr"])),border=NA,col=blues9[3])
lines(new.x,pred[,"fit"],lwd=2,col=blues9[8])
#points(x,y,pch=16)
#box()
#https://www.researchgate.net/post/How_can_I_put_confidence_intervals_in_R_plot
```




d. How does a polynomial regression differ both statistically and substantively from a linear regression
```{r 2d}
#F-test
#use ANOVA
#https://www.youtube.com/watch?v=ZYN0YD7UfK4
```
